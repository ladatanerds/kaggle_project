{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp.features import create_train_features\n",
    "from exp.run import run_experiment\n",
    "from exp.mappings import alg_map\n",
    "from exp.train import train_model\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_tr, y_tr = create_train_features(r'C:\\Users\\arvin\\dev\\lanl\\train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example hyper-parameter experiments for different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\"lr\": {\"fit_intercept\": [False, True], \"normalize\": [False, True]},\n",
    "       \"ridge\": {\"alpha\": [.000001, .00001, .0001, .001, .01, .1],\n",
    "                 \"fit_intercept\": [False, True], \"normalize\": [False, True]},\n",
    "       \"lasso\": {\"alpha\": [.000001, .00001, .0001, .001, .01, .1],\n",
    "                 \"fit_intercept\": [False, True], \"normalize\": [False, True]},\n",
    "       \"elastic\": {\"alpha\": [.000001, .00001, .0001, .001, .01, .1],\n",
    "                   \"fit_intercept\": [False, True], \"normalize\": [False, True],\n",
    "                  \"l1_ratio\": [.01, .99, .2, .4, .6, .8]},\n",
    "       \"dtreg\": {\"criterion\": [\"mse\", \"friedman_mse\", \"mae\"],\n",
    "                 \"splitter\": [\"best\", \"best\", \"random\"],\n",
    "                \"max_depth\": [None, None, None, 5,10,20,50]},\n",
    "       \"rfreg\": {\"n_estimators\": [5, 10, 50, 100, 200, 100],\n",
    "                 \"criterion\": [\"mse\", \"friedman_mse\", \"mae\"],\n",
    "                 \"splitter\": [\"best\", \"best\", \"random\"],\n",
    "                \"max_depth\": [None, None, None, 5,10,20,50]},\n",
    "       \"abreg\": {\"n_estimators\": [5, 10, 50, 100, 200, 100],\n",
    "                 \"learning_rate \": [1, .9, .5, .1],\n",
    "                 \"loss\": [\"linear\", \"square\", \"exponential\"]},\n",
    "       \"gbreg\": {\"n_estimators\": [5, 10, 50, 100, 200, 100],\n",
    "                 \"learning_rate \": [1, .9, .5, .1],\n",
    "                 \"loss\": [\"ls\", \"lad\", \"huber\", \"quantile\"],\n",
    "                 \"subsample\": [.1, .2, .5, 1.0]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Experiment (for Ridge algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg = \"lr\"\n",
    "n_fold=10\n",
    "save_results= \"results.csv\"\n",
    "score_df = run_experiment(X=X_tr, Y=y_tr, n_fold=n_fold, alg=alg, alg_params=params[alg], search_type=\"random\", num_searches=2, save_results=save_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Experiment (for Elastic algorithm) and append to CSV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg = \"elastic\"\n",
    "score_df = run_experiment(score_df=save_results, X=X_tr, Y=y_tr, n_fold=n_fold, alg=alg, alg_params=params[alg], search_type=\"random\", num_searches=2, save_results=save_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display models ranked by CV scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = score_df.sort_values(by=\"score\", axis=0)\n",
    "display(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results from CSV File and re-produce models ranked by CV scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.read_csv(save_results)\n",
    "score_df = score_df.sort_values(by=\"score\", axis=0)\n",
    "display(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best model from CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve top scoring row\n",
    "best = score_df.iloc[0]\n",
    "display(best)\n",
    "\n",
    "# retrieve model parameters from pandas row\n",
    "alg = best[\"alg\"]\n",
    "params_json = best[\"params_json\"]\n",
    "print(\"alg: {}\".format(alg))\n",
    "print(\"params_json: {}\".format(params_json))\n",
    "\n",
    "# retrieve relevant values\n",
    "alg_cls = alg_map[alg]\n",
    "params = json.loads(params_json)\n",
    "\n",
    "# initialize model\n",
    "model = alg_cls(**params)\n",
    "\n",
    "# train algorithm\n",
    "train_model(X=X_tr, Y=y_tr, n_fold=n_fold, model=model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
